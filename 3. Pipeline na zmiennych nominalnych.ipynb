{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zmienne kategoryczne w sklearn + szybki ogląd danych\n",
    "\n",
    "Sci-kit learn w obecnej wersji wymaga, aby ramka dostarczana do metody `.fit` zawierała *tylko* wartości  numeryczne (kolumny boolowe zostaną zrzutowane do wartości `[1, 0]`). Oczekuje się więc od użytkownika, że cechy zawierające typ `string`, czy `datetime` zostaną zakodowane tak, aby klasyfikator mógł wyekstrahować informację zawartą w danych. Ale **UWAGA:** nie możemy z góry założyć, że jeśli kolumna zawiera wartość numeryczną (w szczególności: `int`), to że automatycznie nie jest nominalna.\n",
    "\n",
    "Zaczniemy od przejrzenia wartości w poszczególnych kolumnach naszych danych treningowych. Chcemy znaleźć cechy nominalne (kategoryczne), które następnie pogrupujemy ze względu na typ, liczbę unikatowych wartości, oraz inne kryteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_and_y_train = pd.concat([pd.read_csv('data/xtrain_1.csv'),\n",
    "                           pd.read_csv('data/xtrain_2.csv'),\n",
    "                           pd.read_csv('data/y_train.csv', header=None, names=['y'])],\n",
    "                          axis=1)\n",
    "\n",
    "x_and_y_train['received_at'] = pd.to_datetime(x_and_y_train['received_at'])\n",
    "\n",
    "x_and_y_train = x_and_y_train.sort_values('received_at')\n",
    "\n",
    "ytrain = x_and_y_train.pop('y')\n",
    "xtrain = x_and_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for colname in sorted(xtrain.columns):\n",
    "    not_nones = xtrain[colname][pd.notnull(xtrain[colname])]\n",
    "    has_complex_types = any(not_nones.apply(lambda x: isinstance(x, (dict, list))))\n",
    "    is_not_Series = not isinstance(not_nones, pd.Series)\n",
    "    if has_complex_types or is_not_Series:\n",
    "        continue\n",
    "    unique_values = not_nones.unique()\n",
    "    print('{} ({}): {}'.format(colname, len(unique_values), unique_values[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_card_cat_colnames = [\n",
    "                    'agent_type', 'bin_country', 'browser', 'browser_string_mismatch',\n",
    "                    'card_brand', 'card_level', 'card_type', 'cc_bin_number_brand', 'cc_bin_number_type',\n",
    "                    'cc_number_hash_assert_history', 'cc_number_hash_result', 'input_ip_assert_history',\n",
    "                    'input_ip_geo', 'input_ip_result', 'js_browser', 'js_fonts_number', 'js_os', 'navigatorplatform',\n",
    "                    'os', 'remote_desktop', 'request_result', 'review_status', 'x10047', 'x12050', 'x16453', \n",
    "                    'x21202', 'x21215', 'x21877', 'x26431', 'x32520', 'x39150', 'x41009', 'x5170', 'x5193',\n",
    "                    'x5290', 'x5342', 'x55586', 'x66439', 'x70617', 'x72496', 'x73629', 'x80025', 'x80385',\n",
    "                    'x80911', 'x83032', 'x83336', 'x91746', 'x92645', 'x96255', \n",
    "                   ]\n",
    "                    \n",
    "                    \n",
    "high_card_cat_colnames = [\n",
    "                    'bin', 'browser_string_hash', 'cc_bin_number', 'cc_bin_number_category', 'cc_bin_number_geo',\n",
    "                    'cc_bin_number_org', 'country_code', 'dns_ip_city', 'dns_ip_isp', 'dns_ip_organization',\n",
    "                    'dns_ip_region', 'input_ip_city', 'js_browser_string_hash', 'js_fonts_hash', 'language',\n",
    "                    'mime_type_hash', 'name', 'user_ip_country', 'x12964', 'x18591', 'x2801', 'x30901', 'x33709',\n",
    "                    'x46567', 'x46591', 'x52094', 'x55037', 'x61305', 'x63143', 'x66015', 'x76585', 'x82598',\n",
    "                    'x87611', 'x92166', 'x92221', 'x94347', \n",
    "                    ]\n",
    "                    \n",
    "parsable_cat_colnames = [\n",
    "                    'browser_string', 'headers_accept_encoding', 'headers_accept_language', 'headers_user_agent',\n",
    "                    'input_ip_attributes', 'js_browser_string', 'navigatorappversion', 'useragent', 'x31255',\n",
    "                    'x50315', \n",
    "                    ]\n",
    "                    \n",
    "degree_cat_colnames = ['risk_rating']\n",
    "                    \n",
    "castable_to_numeric_cat_colnames = [\n",
    "                    'x23739', 'x3314', 'x42317', 'x43300', 'x44170', 'x48420', 'x51274', 'x54084',\n",
    "                    'x5600', 'x59752', 'x60781', 'x87918', 'x9486', 'x97674', 'x98509',\n",
    "                    'application_id'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele budowane na zmiennych kategorycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, RidgeClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "from hash_transformers import SimplisticHasher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Modele budowane na `low_card_cat_colnames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_cat = xtrain[low_card_cat_colnames]\n",
    "DF_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WAŻNA UWAGA:** zwróćcie uwagę, że metoda podziału na treningowy/walidacyjny używana poniżej (`TimeSeriesSplit`) **zakłada**, że ramka jest posortowana wg odpowiedniej kolumny czasowej (tutaj: `received_at`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_colnames = DF_cat.columns.tolist()\n",
    "\n",
    "pipe = Pipeline([\n",
    "#     ('hashing_trick', ce.HashingEncoder(cols=cat_colnames, n_components=10*len(cat_colnames))),\n",
    "    ('simplistic_hash', SimplisticHasher(cols=cat_colnames)),\n",
    "    \n",
    "    ('imputer', Imputer(missing_values=pd.np.nan, strategy='most_frequent', axis=0)),    \n",
    "#     ('xgb', XGBClassifier()),\n",
    "    ('log_reg', LogisticRegression()),\n",
    "#     ('lin_reg', LinearRegression()),\n",
    "#     ('ridge', RidgeClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "scores = cross_val_score(pipe,\n",
    "                         DF_cat,\n",
    "                         ytrain,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=TimeSeriesSplit(6))\n",
    "\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele budowane na `[low_card_cat_colnames, high_card_cat_colnames]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_cat = xtrain[low_card_cat_colnames+high_card_cat_colnames]\n",
    "\n",
    "cat_colnames = DF_cat.columns.tolist()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('hashing_trick', ce.HashingEncoder(cols=cat_colnames, n_components=10*len(cat_colnames))),\n",
    "#     ('simplistic_hash', SimplisticHasher(cols=cat_colnames)),\n",
    "    \n",
    "#     ('imputer', Imputer(missing_values=pd.np.nan, strategy='most_frequent', axis=0)),    \n",
    "    ('xgb', XGBClassifier()),\n",
    "#     ('log_reg', LogisticRegression()),\n",
    "#     ('lin_reg', LinearRegression()),\n",
    "#     ('ridge', RidgeClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "scores = cross_val_score(pipe,\n",
    "                         DF_cat,\n",
    "                         ytrain,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=TimeSeriesSplit(6))\n",
    "\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kolumny zawierające słowniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undict_one_col(df, colname):\n",
    "    column = df.pop(colname)\n",
    "    values = [dict() if x is None else x for x in column]\n",
    "    unpacked_columns = pd.DataFrame.from_dict(values)\n",
    "    unpacked_columns = unpacked_columns.add_prefix(colname + '_')\n",
    "    return pd.concat([df, unpacked_columns], axis=1)\n",
    "\n",
    "def undict_cols(df, col_names):\n",
    "    for col_name in col_names:\n",
    "        df = undict_one_col(df, col_name)    \n",
    "    return df\n",
    "\n",
    "\n",
    "dict_counts = xtrain.apply(lambda col: col.apply(lambda x: isinstance(x, dict))).sum()\n",
    "dict_colnames = dict_counts[dict_counts>0].index.tolist()\n",
    "\n",
    "xtrain_undicted = undict_cols(xtrain[dict_colnames], dict_colnames)\n",
    "xtrain_undicted_numeric = xtrain_undicted.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model zbudowany na zmiennych kategorycznych + numerycznych ze słowników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_cat_and_undict = pd.concat([DF_cat, xtrain_undicted_numeric], axis=1)\n",
    "cat_colnames = DF_cat_and_undict.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "DF_cat_and_undict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipe,\n",
    "                         DF_cat_and_undict,\n",
    "                         ytrain,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=TimeSeriesSplit(6))\n",
    "\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odnośniki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding i algorytmy drzewiaste\n",
    "Post: http://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/ omawia przykład, w którym kodowanie zmiennych nominalnych przy użyciu OHE porównywane jest z kodowaniem wykorzystywanym domyślnie w bibliotece H2O (http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/nbins_cats.html). Dodatkowo: paragraf *4.6 Treatment of factors* w opisie GBMów w H2O https://h2o-release.s3.amazonaws.com/h2o/master/3153/docs-website/h2o-docs/booklets/GBM_Vignette.pdf\n",
    "\n",
    "\n",
    "\n",
    "#### Wykład Owena Zhanga\n",
    "https://www.youtube.com/watch?v=LgLcfZjNF44, w którym mowa o: GBMach, kodowaniu zmiennych nominalnych, licznych \"sztuczkach\" przydatnych w konkursach kaggle'owych. \n",
    "\n",
    "\n",
    "\n",
    "#### GBMy w ramach Distributed Machine Learning Toolkit\n",
    "https://github.com/Microsoft/LightGBM; w swoim benchmarku autorzy twierdzą, LightGBM daje w niektórych przypadkach lepsze wyniki, niż XGBoost (https://github.com/Microsoft/LightGBM/wiki/Experiments#comparison-experiment).\n",
    "\n",
    "\n",
    "\n",
    "#### Pull request na repo sklearnowym odn. wprowadzenia natywnego wsparcia dla zmiennych kategorycznych\n",
    "https://github.com/scikit-learn/scikit-learn/pull/4899\n",
    "\n",
    "\n",
    "\n",
    "#### Repo paczki `category_encoders`\n",
    "https://github.com/scikit-learn-contrib/categorical-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praca domowa\n",
    "(do wykonania grupowo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Zbierzcie powielone kawałki kodu z tego notatnika i opakujcie je w funkcje, które będą w plikach `.py` (tak, żeby można je było importować);\n",
    "\n",
    "1. Przejrzyjcie pozostałe typy zmiennych kategorycznych (`parsable_cat_colnames, degree_cat_colnames, castable_to_numeric_cat_colnames`) i wybierzcie te, które chcecie jeszcze dodać do danych treningowych;\n",
    "\n",
    "2. Rozpakujcie kolumny zawierające wartości typu `list` (polecam szczególnie kolumnę `'flash_fonts'`);\n",
    "\n",
    "3. Wypróbujcie inne klasyfikatory (`sklearn.ensemble.AdaBoostClassifier`, `sklearn.svm.SVC`);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przypomnienie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli chcecie popracować na AWSie w domu, ustalcie jaki termin by Wam najbardziej pasował i dajcie znać na maila: **maciej.dziubinski@daftcode.pl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
